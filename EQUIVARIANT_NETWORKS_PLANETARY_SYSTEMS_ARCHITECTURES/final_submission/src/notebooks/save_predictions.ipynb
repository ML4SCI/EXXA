{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T18:50:43.771333Z",
     "iopub.status.busy": "2024-09-19T18:50:43.770903Z",
     "iopub.status.idle": "2024-09-19T18:50:47.132625Z",
     "shell.execute_reply": "2024-09-19T18:50:47.131379Z",
     "shell.execute_reply.started": "2024-09-19T18:50:43.771288Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T18:50:47.136455Z",
     "iopub.status.busy": "2024-09-19T18:50:47.136067Z",
     "iopub.status.idle": "2024-09-19T18:50:49.649500Z",
     "shell.execute_reply": "2024-09-19T18:50:49.648359Z",
     "shell.execute_reply.started": "2024-09-19T18:50:47.136412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!apt-get install build-essential libatomic1 gfortran perl wget m4 cmake pkg-config curl -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-19T18:52:29.025405Z",
     "iopub.status.busy": "2024-09-19T18:52:29.024976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "from models.models import EquivariantVgg16\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.dataset import PlanetaryDataset\n",
    "from utilities.training import VAL_TEST_TRANSFORM\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 4 models per chunk (so that the memory doesn't run out)\n",
    "models = {\n",
    "    \"/kaggle/input/vgg16-models/pytorch/default/2/model_channels_30_31_32_33_34_35.pt\": EquivariantVgg16(\n",
    "        num_classes=2\n",
    "    ),\n",
    "    \"/kaggle/input/vgg16-models/pytorch/default/2/model_channels_36_37_38_39_40_41.pt\": EquivariantVgg16(\n",
    "        num_classes=2\n",
    "    ),\n",
    "    \"/kaggle/input/vgg16-models/pytorch/default/2/model_channels_42_43_44_45_46_47.pt\": EquivariantVgg16(\n",
    "        num_classes=2\n",
    "    ),\n",
    "    \"/kaggle/input/vgg16-models/pytorch/default/2/model_channels_48_49_50_51_52_53.pt\": EquivariantVgg16(\n",
    "        num_classes=2\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def evaluate_and_save_predictions(models, dataset, device, pred_file, prob_file):\n",
    "    test_loader = DataLoader(\n",
    "        dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True\n",
    "    )\n",
    "\n",
    "    all_predictions = {}\n",
    "    all_probabilities = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for model_path, model in models.items():\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            predictions = []\n",
    "            probabilities = []\n",
    "\n",
    "            for batch in test_loader:\n",
    "                images, labels = batch\n",
    "                images = images.to(device)\n",
    "\n",
    "                # Run inference\n",
    "                logits = model(images)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                preds = torch.argmax(probs, dim=1)\n",
    "                print(f\"Probs: {probs}\")\n",
    "\n",
    "                predictions.append(preds.cpu().numpy())\n",
    "                probabilities.append(probs.cpu().numpy())\n",
    "\n",
    "            all_predictions[model_path] = predictions\n",
    "            all_probabilities[model_path] = probabilities\n",
    "\n",
    "    with open(pred_file, \"wb\") as f_pred, open(prob_file, \"wb\") as f_prob:\n",
    "        pickle.dump(all_predictions, f_pred)\n",
    "        pickle.dump(all_probabilities, f_prob)\n",
    "\n",
    "\n",
    "test_dataset = PlanetaryDataset(\n",
    "    data_dir=\"/kaggle/input/gsoc-protoplanetary-disks/Test_Clean\",\n",
    "    csv_file=\"/kaggle/input/gsoc-protoplanetary-disks/test_info.csv\",\n",
    "    channels=list(range(30, 101)),\n",
    "    transform=VAL_TEST_TRANSFORM,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "evaluate_and_save_predictions(\n",
    "    models,\n",
    "    test_dataset,\n",
    "    device,\n",
    "    \"model_1_4_predictions.pkl\",\n",
    "    \"model_1_4_probabilities.pkl\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5412597,
     "sourceId": 9051885,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 121918,
     "modelInstanceId": 97729,
     "sourceId": 116752,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

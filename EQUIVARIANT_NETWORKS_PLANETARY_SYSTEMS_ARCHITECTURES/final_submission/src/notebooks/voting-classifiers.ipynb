{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-19T20:01:31.302622Z",
     "iopub.status.busy": "2024-09-19T20:01:31.302272Z",
     "iopub.status.idle": "2024-09-19T20:01:35.276531Z",
     "shell.execute_reply": "2024-09-19T20:01:35.275392Z",
     "shell.execute_reply.started": "2024-09-19T20:01:31.302583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\n",
    "    \"/kaggle/input/vgg16-models-predictions-test-set/model_1_4_predictions.pkl\", \"rb\"\n",
    ") as f_pred1, open(\n",
    "    \"/kaggle/input/vgg16-models-predictions-test-set/model_1_4_probabilities.pkl\", \"rb\"\n",
    ") as f_prob1:\n",
    "    predictions_1_4 = pickle.load(f_pred1)\n",
    "    probabilities_1_4 = pickle.load(f_prob1)\n",
    "\n",
    "with open(\n",
    "    \"/kaggle/input/vgg16-models-predictions-test-set/model_5_8_predictions.pkl\", \"rb\"\n",
    ") as f_pred2, open(\n",
    "    \"/kaggle/input/vgg16-models-predictions-test-set/model_5_8_probabilities.pkl\", \"rb\"\n",
    ") as f_prob2:\n",
    "    predictions_5_8 = pickle.load(f_pred2)\n",
    "    probabilities_5_8 = pickle.load(f_prob2)\n",
    "\n",
    "with open(\n",
    "    \"/kaggle/input/vgg16-models-predictions-test-set/model_9_12_predictions.pkl\", \"rb\"\n",
    ") as f_pred3, open(\n",
    "    \"/kaggle/input/vgg16-models-predictions-test-set/model_9_12_probabilities.pkl\", \"rb\"\n",
    ") as f_prob3:\n",
    "    predictions_9_12 = pickle.load(f_pred3)\n",
    "    probabilities_9_12 = pickle.load(f_prob3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T20:02:49.132710Z",
     "iopub.status.busy": "2024-09-19T20:02:49.132245Z",
     "iopub.status.idle": "2024-09-19T20:02:49.144407Z",
     "shell.execute_reply": "2024-09-19T20:02:49.143284Z",
     "shell.execute_reply.started": "2024-09-19T20:02:49.132645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from dataset.dataset import PlanetaryDataset\n",
    "from utilities.training import VAL_TEST_TRANSFORM\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataset = PlanetaryDataset(\n",
    "    data_dir=\"/kaggle/input/gsoc-protoplanetary-disks/Test_Clean\",\n",
    "    csv_file=\"/kaggle/input/gsoc-protoplanetary-disks/test_info.csv\",\n",
    "    channels=list(range(30, 101)),\n",
    "    transform=VAL_TEST_TRANSFORM,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T20:04:02.551359Z",
     "iopub.status.busy": "2024-09-19T20:04:02.550415Z",
     "iopub.status.idle": "2024-09-19T20:04:02.557392Z",
     "shell.execute_reply": "2024-09-19T20:04:02.556220Z",
     "shell.execute_reply.started": "2024-09-19T20:04:02.551315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "all_predictions = {**predictions_1_4, **predictions_5_8, **predictions_9_12}\n",
    "all_probabilities = {**probabilities_1_4, **probabilities_5_8, **probabilities_9_12}\n",
    "\n",
    "\n",
    "all_labels = []\n",
    "all_majority_preds = []\n",
    "all_soft_probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T20:04:21.171864Z",
     "iopub.status.busy": "2024-09-19T20:04:21.171453Z",
     "iopub.status.idle": "2024-09-19T20:05:15.835077Z",
     "shell.execute_reply": "2024-09-19T20:05:15.833704Z",
     "shell.execute_reply.started": "2024-09-19T20:04:21.171827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(test_loader):\n",
    "    print(i)\n",
    "    _, labels = batch\n",
    "    all_labels.append(labels.item())\n",
    "\n",
    "    # collect predictions from all models\n",
    "    sample_preds = []\n",
    "    sample_probs = []\n",
    "    for model_path, preds in all_predictions.items():\n",
    "        sample_preds.append(preds[i])\n",
    "    for model_path, probs in all_probabilities.items():\n",
    "        sample_probs.append(probs[i])\n",
    "\n",
    "    # Hard Voting\n",
    "    stacked_preds = np.stack(sample_preds)\n",
    "    majority_pred = np.argmax(np.bincount(stacked_preds.flatten()))\n",
    "    all_majority_preds.append(majority_pred)\n",
    "\n",
    "    # Soft Voting\n",
    "    stacked_probs = np.stack(sample_probs)\n",
    "    avg_probs = np.mean(stacked_probs, axis=0)\n",
    "    soft_pred = np.argmax(avg_probs)\n",
    "    all_soft_probs.append(avg_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard and soft accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T20:08:30.691828Z",
     "iopub.status.busy": "2024-09-19T20:08:30.691389Z",
     "iopub.status.idle": "2024-09-19T20:08:30.709105Z",
     "shell.execute_reply": "2024-09-19T20:08:30.708034Z",
     "shell.execute_reply.started": "2024-09-19T20:08:30.691786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy for hard voting\n",
    "accuracy_hard = np.mean(np.array(all_majority_preds) == np.array(all_labels))\n",
    "print(f\"Hard Voting Accuracy: {accuracy_hard * 100:.2f}%\")\n",
    "\n",
    "\n",
    "all_soft_probs_array = np.array(all_soft_probs)\n",
    "\n",
    "avg_soft_probs = np.mean(all_soft_probs_array, axis=0)\n",
    "\n",
    "soft_pred_labels = np.argmax(avg_soft_probs, axis=1)\n",
    "accuracy_soft = np.mean(soft_pred_labels == np.array(all_labels))\n",
    "print(f\"Soft Voting Accuracy: {accuracy_soft * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save incorrect samples indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T20:08:39.910989Z",
     "iopub.status.busy": "2024-09-19T20:08:39.909999Z",
     "iopub.status.idle": "2024-09-19T20:08:39.916496Z",
     "shell.execute_reply": "2024-09-19T20:08:39.915474Z",
     "shell.execute_reply.started": "2024-09-19T20:08:39.910930Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "incorrect_samples_hard = np.where(np.array(all_majority_preds) != np.array(all_labels))[\n",
    "    0\n",
    "]\n",
    "incorrect_samples_soft = np.where(soft_pred_labels != np.array(all_labels))[0]\n",
    "\n",
    "with open(\"incorrect_samples_hard.pkl\", \"wb\") as f_hard, open(\n",
    "    \"incorrect_samples_soft.pkl\", \"wb\"\n",
    ") as f_soft:\n",
    "    pickle.dump(incorrect_samples_hard, f_hard)\n",
    "    pickle.dump(incorrect_samples_soft, f_soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong predictions visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T20:09:28.794414Z",
     "iopub.status.busy": "2024-09-19T20:09:28.793696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "with open(\"/kaggle/working/incorrect_samples_hard.pkl\", \"rb\") as f_hard, open(\n",
    "    \"/kaggle/working/incorrect_samples_soft.pkl\", \"rb\"\n",
    ") as f_soft:\n",
    "    incorrect_samples_hard = pickle.load(f_hard)\n",
    "    incorrect_samples_soft = pickle.load(f_soft)\n",
    "\n",
    "\n",
    "def plot_images(dataset, indices, title, num_cols=5):\n",
    "    num_rows = len(indices) // num_cols + 1\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 3 * num_rows))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, _ = dataset[idx]\n",
    "        ax = axes[i // num_cols, i % num_cols]\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        ax.set_title(f\"Sample {idx}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_images(test_dataset, incorrect_samples_hard, \"Hard Voting Misclassifications\")\n",
    "plot_images(test_dataset, incorrect_samples_soft, \"Soft Voting Misclassifications\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5734847,
     "sourceId": 9437856,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5412597,
     "sourceId": 9051885,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
